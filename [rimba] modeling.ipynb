{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"FI1RES95Gzc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !git clone https://github.com/smousavi05/EQTransformer"],"metadata":{"id":"USpKoVS_OMqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !cd EQTransformer; python setup.py install"],"metadata":{"id":"Iv7H1WKShCIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# os.rename('EQTransformer', 'EQTransformer_')"],"metadata":{"id":"Yp6d50t1mHsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !mv EQTransformer_/EQTransformer ."],"metadata":{"id":"zIPnNkfhmnqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install obspy\n","# restart runtime after installing this"],"metadata":{"id":"pyK-WR3OnAon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_training_chart(history, key, figsize=None):\n","  figsize = figsize or (10, 5)\n","  epochs = [i for i in history.epoch]\n","  fig , ax = plt.subplots(1, 1, figsize=figsize)\n","  train_metrics = history.history[key]\n","  val_metrics = history.history['val_' + key]\n","  if key =='loss':\n","    train_metrics = np.array(train_metrics)/sum(train_metrics)\n","    val_metrics = np.array(val_metrics)/sum(val_metrics)\n","  ax.plot(epochs , train_metrics , label = f'Training {key}')\n","  ax.plot(epochs , val_metrics, label = f'Validation {key}')\n","  ax.set_title(f'Training & validation {key}')\n","  ax.legend()\n","  ax.set_xlabel(\"Epochs\")\n","  ax.set_ylabel(f\"{key}\")\n","  plt.show()\n","\n","def plot_stream(dset, p, s, eq, \n","                is_test=False, thres=.5, \n","                figsize=None):\n","  fig, ax = plt.subplots(4 if is_test else 3,1, figsize=(figsize))\n","  plt.tight_layout()\n","\n","  for i in range(3):\n","    ymin, ymax = ax[i].get_ylim()\n","    xtr = ax[i].get_xaxis_transform()  \n","    ax[i].plot(np.array(dset)[:,i], 'k')\n","    ax[i].vlines(dset.attrs['p_arrival_sample'], ymin, ymax, color='b', transform=xtr, label='P-arrival')\n","    ax[i].vlines(dset.attrs['s_arrival_sample'], ymin, ymax, color='r', transform=xtr, label='S-arrival')\n","    ax[i].vlines(dset.attrs['coda_end_sample'], ymin, ymax, color='aqua', transform=xtr, label='Coda End')\n","    ax[i].set_xticklabels([])\n","    ax[i].set_ylabel('Amplitude')\n","    plt.tight_layout()\n","    if i==0:\n","      ax[i].set_title(ev)\n","\n","  if is_test:\n","    p_p,s_p,eq_p = p.copy(), s.copy(), eq.copy()\n","    p_p[p_p<thres] = 0\n","    s_p[s_p<thres] = 0\n","    eq_p[eq_p<thres] = 0\n","\n","    ax[3].plot(p_p, 'b--', label='P_arrival')\n","    ax[3].plot(s_p, 'r--', label='S_arrival')\n","    ax[3].plot(eq_p, 'g--', label='Earthquake')\n","    ax[3].set_ylabel('Probability')\n","    plt.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05), ncol=3)\n","    plt.tight_layout()\n"],"metadata":{"id":"a0Blk53LZuvQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks/Eq_Detection"],"metadata":{"id":"4CUFonGb0-VC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"zEsi2mVm1LG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","import os\n","\n","csv_path = os.path.join('data','chunk2_ev.1069.csv')\n","h5_path = os.path.join('data','chunk2_ev.1069.hdf5')\n","metadata = pd.read_csv(csv_path)\n","ev_list = metadata['trace_name'].to_list()\n","\n","h5 = h5py.File(h5_path, 'r')\n","for ev in ev_list[:3]:\n","  dset = h5.get(f'data/{ev}')\n","  times = np.array(dset.attrs['times'])\n","  p = dset.attrs['p_arrival_sample']\n","  s = dset.attrs['s_arrival_sample']\n","  eq = dset.attrs['coda_end_sample']\n","  \n","  plot_stream(dset, p,s,eq)\n","\n","  # export an event as a csv\n","  # p_time = dset.attrs['p_arrival_sample'].astype(int)\n","  # coda_time = dset.attrs['coda_end_sample'][0][0].astype(int)\n","\n","  # y_ = np.zeros((len(times),))\n","  # y_[p_time:coda_time+1] = 1\n","  # y_\n","\n","  # dfd = {'timestamp': times, 'is_eq': y_.astype(int)}\n","  # for i,c in enumerate(['HHE', 'HHN', 'HHZ']):\n","  #   dfd[c] = np.array(dset)[:,i]\n","\n","  # out_path = os.path.join('data', 'csv', f'{ev}.csv')\n","  # pd.DataFrame(dfd).to_csv(out_path, index=None)"],"metadata":{"id":"eqqJEG2xHEQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TIMESTEPS = 6000\n","\n","X, label_p, label_s, label_eq = [], [], [], []\n","\n","for ev in ev_list:\n","    dset = h5.get(f'data/{ev}')\n","\n","    X.append(np.array(dset))\n","\n","    y_ = np.zeros((TIMESTEPS,))\n","    time_p = dset.attrs['p_arrival_sample'].astype(int)\n","    y_[time_p] = 1.0\n","    label_p.append(y_.astype(int))\n","\n","    y_ = np.zeros((TIMESTEPS,))\n","    y_[dset.attrs['s_arrival_sample'].astype(int)] = 1.0\n","    label_s.append(y_.astype(int))\n","        \n","    y_ = np.zeros((TIMESTEPS,))\n","    y_[time_p:dset.attrs['coda_end_sample'][0][0].astype(int)+1] = 1.0\n","    label_eq.append(y_.astype(int))\n","\n","X = np.array(X)\n","label_p = np.expand_dims(label_p, axis=-1)\n","label_s = np.expand_dims(label_s, axis=-1)\n","label_eq = np.expand_dims(label_eq, axis=-1)\n","\n","train_size = int(len(X)*.8)\n","X_train, X_test = X[:train_size], X[train_size:]\n","p_train, p_test = label_p[:train_size], label_p[train_size:]\n","s_train, s_test = label_s[:train_size], label_s[train_size:]\n","eq_train, eq_test = label_eq[:train_size], label_eq[train_size:]"],"metadata":{"id":"RKW4nKPyhH0u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LSTM"],"metadata":{"id":"VeTEAzOpxyuj"}},{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"id":"n2lQs16SCek3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","from keras.layers import LSTM, Dense, Input\n","\n","def model_LSTM(lstm_blocks=1, dense_blocks=1, lstm_units=32, dense_units=32, lr=.001, **kwargs):\n","  input_shape = (TIMESTEPS, 3)\n","  inputs = Input(shape=input_shape, name='input')\n","  lstm = inputs\n","  for lb in range(lstm_blocks):\n","    lstm = LSTM(lstm_units, return_sequences=True, name='lstm_'+str(lb+1))(lstm)\n","\n","  dense_p = lstm\n","  dense_s = lstm\n","  dense_eq = lstm\n","  for db in range(dense_blocks):\n","    dense_p  = Dense(dense_units, activation='relu', name='P_'+str(db+1))(dense_p)\n","    dense_s  = Dense(dense_units, activation='relu', name='S_'+str(db+1))(dense_s)\n","    dense_eq = Dense(dense_units, activation='relu', name='Eq_'+str(db+1))(dense_eq)\n","\n","  dense_p = Dense(1, activation='sigmoid', name='P')(dense_p)\n","  dense_s = Dense(1, activation='sigmoid', name='S')(dense_s)\n","  dense_eq = Dense(1, activation='sigmoid', name='Eq')(dense_eq)\n","\n","  model = tf.keras.Model(inputs=inputs, outputs=[dense_p, dense_s, dense_eq])\n","\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=lr, **kwargs)\n","  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['mae'])\n","  model.summary()\n","  return model"],"metadata":{"id":"SQvZ-5SoBLpU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tunning Hyperparameter\n"," - lstm_blocks: 1, dense_blocks: 1\n"," - lstm_blocks: 1, dense_blocks: 2\n"," - lstm_blocks: 2, dense_blocks: 2\n"," - lstm_blocks: 2, dense_blocks: 2"],"metadata":{"id":"SX6QrSksl7Lk"}},{"cell_type":"markdown","source":["l_block = 1, dense_block = 1"],"metadata":{"id":"p9BjgWQ2DPJq"}},{"cell_type":"code","source":["es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) \n","lstm_1_1 = model_LSTM(lstm_blocks=1, dense_blocks=1)\n","\n","class_weights = {\n","    'P': {0: .11, 1: .89}, \n","    'S': {0: .11, 1: .89}, \n","    'Eq': {0: .2, 1: .8}\n","    }\n","hist_1_1 = lstm_1_1.fit(X_train, [p_train, s_train, eq_train], epochs=2, batch_size=128, \n","                validation_split=0.1, callbacks=[es])"],"metadata":{"id":"iz0AGmbRDXPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training_chart(hist_1_1, 'loss')"],"metadata":{"id":"UDCet-Q3DkbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_1_1.evaluate(X_test, [p_test, s_test, eq_test])"],"metadata":{"id":"cVlpeCpFDoff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_pred_1_1, s_pred_1_1, eq_pred_1_1 = lstm_1_1.predict(X_test)"],"metadata":{"id":"tQdPOGUGDt9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i_test = train_size + 8\n","\n","dset = h5.get(f'data/{ev_list[i_test]}')\n","it = i_test-train_size\n","p = np.squeeze(p_pred_1_1, axis=2)[it]\n","s = np.squeeze(s_pred_1_1, axis=2)[it]\n","eq = np.squeeze(eq_pred_1_1, axis=2)[it]\n","\n","plot_stream(dset, p, s, eq, is_test=True, thres=.3, figsize=(10,8))"],"metadata":{"id":"681BTj4aDxwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_1_1.save('lstm_l1_d1.h5')"],"metadata":{"id":"CPcyoagIs7R9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(np.absolute(p_pred_1_1 - p_test))"],"metadata":{"id":"bcLBbSreD1-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_test.shape"],"metadata":{"id":"g4yq-EqFD4pE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["l_block = 1, dense_block = 2"],"metadata":{"id":"eDSTOIzDDYMP"}},{"cell_type":"code","source":["es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) \n","lstm_1_2 = model_LSTM(lstm_blocks=1, dense_blocks=1)\n","\n","class_weights = {\n","    'P': {0: .11, 1: .89}, \n","    'S': {0: .11, 1: .89}, \n","    'Eq': {0: .2, 1: .8}\n","    }\n","hist_1_2 = lstm_1_2.fit(X_train, [p_train, s_train, eq_train], epochs=50, batch_size=128, \n","                validation_split=0.1, callbacks=[es])"],"metadata":{"id":"TYLa-HVhGGIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training_chart(hist_1_2, 'loss')"],"metadata":{"id":"zCelNZ2gW2nE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_1_2.evaluate(X_test, [p_test, s_test, eq_test])"],"metadata":{"id":"VmuKEtpaW2nE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_pred_1_2, s_pred_1_2, eq_pred_1_2 = lstm_1_2.predict(X_test)"],"metadata":{"id":"PpepsjWRW2nE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i_test = train_size + 8\n","\n","dset = h5.get(f'data/{ev_list[i_test]}')\n","it = i_test-train_size\n","p = np.squeeze(p_pred_1_2, axis=2)[it]\n","s = np.squeeze(s_pred_1_2, axis=2)[it]\n","eq = np.squeeze(eq_pred_1_2, axis=2)[it]\n","\n","plot_stream(dset, p, s, eq, is_test=True, thres=.3, figsize=(10,8))"],"metadata":{"id":"idXYAKDgW2nF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_1_2.save('lstm_l1_d2.h5')"],"metadata":{"id":"SjoNip-1tHCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(np.absolute(p_pred_1_2 - p_test))"],"metadata":{"id":"oO3g0YIEW2nF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_test.shape"],"metadata":{"id":"pw31guXOW2nF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["l_block = 2, dense_block = 1"],"metadata":{"id":"G8K4qBBlEHIx"}},{"cell_type":"code","source":["es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) \n","lstm_2_1 = model_LSTM(lstm_blocks=1, dense_blocks=1)\n","\n","class_weights = {\n","    'P': {0: .11, 1: .89}, \n","    'S': {0: .11, 1: .89}, \n","    'Eq': {0: .2, 1: .8}\n","    }\n","hist_2_1 = lstm_2_1.fit(X_train, [p_train, s_train, eq_train], epochs=50, batch_size=128, \n","                validation_split=0.1, callbacks=[es])"],"metadata":{"id":"Q0LtbVneGOhg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training_chart(hist_2_1, 'loss')"],"metadata":{"id":"Wx-FlHP-hn04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_2_1.evaluate(X_test, [p_test, s_test, eq_test])"],"metadata":{"id":"DMdXoUORgIuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_pred_2_1, s_pred_2_1, eq_pred_2_1 = lstm_2_1.predict(X_test)"],"metadata":{"id":"t8X0OyqbgIuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i_test = train_size + 8\n","\n","dset = h5.get(f'data/{ev_list[i_test]}')\n","it = i_test-train_size\n","p = np.squeeze(p_pred_2_1, axis=2)[it]\n","s = np.squeeze(s_pred_2_1, axis=2)[it]\n","eq = np.squeeze(eq_pred_2_1, axis=2)[it]\n","\n","plot_stream(dset, p, s, eq, is_test=True, thres=.3, figsize=(10,8))"],"metadata":{"id":"pJRceahrgIuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_2_1.save('lstm_l2_d1.h5')"],"metadata":{"id":"EtXylGvitNx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(np.absolute(p_pred_2_1 - p_test))"],"metadata":{"id":"vhZSydLGgIuv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_test.shape"],"metadata":{"id":"Mgxn9P_DgIuv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["l_block = 2, dense_block = 2\n"],"metadata":{"id":"KJYEA_OaEG7o"}},{"cell_type":"code","source":["es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10) \n","lstm_2_2 = model_LSTM(lstm_blocks=2, dense_blocks=2)\n","\n","class_weights = {\n","    'P': {0: .11, 1: .89}, \n","    'S': {0: .11, 1: .89}, \n","    'Eq': {0: .2, 1: .8}\n","    }\n","hist_2_2 = lstm_2_2.fit(X_train, [p_train, s_train, eq_train], epochs=50, batch_size=128, \n","                validation_split=0.1, callbacks=[es])"],"metadata":{"id":"1Kq2JN2GDHMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training_chart(hist_2_2, 'loss')"],"metadata":{"id":"6jXueZqwGY21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_2_2.evaluate(X_test, [p_test, s_test, eq_test])"],"metadata":{"id":"w10iBO9TmvPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_pred_2_2, s_pred_2_2, eq_pred_2_2 = lstm_2_2.predict(X_test)"],"metadata":{"id":"7ccq5FuWTYbX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i_test = train_size + 8\n","\n","dset = h5.get(f'data/{ev_list[i_test]}')\n","it = i_test-train_size\n","p = np.squeeze(p_pred_2_2, axis=2)[it]\n","s = np.squeeze(s_pred_2_2, axis=2)[it]\n","eq = np.squeeze(eq_pred_2_2, axis=2)[it]\n","\n","plot_stream(dset, p, s, eq, is_test=True, thres=.3, figsize=(10,8))"],"metadata":{"id":"ffzf9wnSTdoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_2_2.save('lstm_l2_d2.h5')"],"metadata":{"id":"vhIlNGy_tUwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(np.absolute(p_pred_2_2 - p_test))"],"metadata":{"id":"VQLmd3hEmaW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p_test.shape"],"metadata":{"id":"YCZdwu2gSXUq"},"execution_count":null,"outputs":[]}]}